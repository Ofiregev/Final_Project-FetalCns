{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ofiregev/Final_Project-FetalCns/blob/main/Fetal_Cns_Final_reg_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Part 1 has done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDNOtD8OuNqn",
        "outputId": "c898bc79-858d-4b44-8aea-91e2b26561a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Part 1 has done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Define CustomDataset Class and Read CSV File\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.data_frame.iloc[idx, 2]  # Assuming the third column is the label\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "0F4wcuObuccv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Determine the available hardware (CPU or GPU) and set the PyTorch device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRkJdLMg1UHT",
        "outputId": "fd94527e-90c5-46a6-df92-0598199bd651"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the list of images from the CSV file\n",
        "train_csv = \"/content/drive/MyDrive/FinalProject/training_set_pixel_size_and_HC.csv\"\n",
        "train_csv_df = pd.read_csv(train_csv)\n"
      ],
      "metadata": {
        "id": "n5SWSktsumWA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_df.head()\n",
        "len(train_csv_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRVsx9GhzmEM",
        "outputId": "146d1c59-67b2-4680-ec76-6e4f1c7f7f43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Define Transforms and Create Dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_dataset = CustomDataset(csv_file=\"/content/drive/MyDrive/FinalProject/training_set_pixel_size_and_HC.csv\",\n",
        "                              root_dir=\"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/\",\n",
        "                              transform=transform)"
      ],
      "metadata": {
        "id": "_1eXQhF2utoI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Create DataLoader\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "IoPz2uS-ux-U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_channels=1, input_size=64):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        conv_output_size = input_size // 2 // 2 // 2 // 2  # Adjusted for additional pooling layers\n",
        "        self.fc1 = nn.Linear(512 * conv_output_size * conv_output_size, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rEfSMMeMu1Nv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_channels=1, input_size=64)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enSvWIyjiQkc",
        "outputId": "04051407-2180-4376-f652-78e5ebc32034"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=8192, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6: Define Training Parameters and Optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "QVo75mLhu49C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)  # Calculate the MSE loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)  # Average loss per epoch\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "sjg4Y0ohjX6W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)  # Calculate the MSE loss\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "    fold_avg_val_loss = np.mean(val_losses)  # Average validation loss\n",
        "    return fold_avg_val_loss"
      ],
      "metadata": {
        "id": "G9u-TeagjYwQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "k = 2\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "evaluation_metrics = []\n",
        "epochs = 2\n",
        "\n",
        "# Define the function to reinitialize the model\n",
        "def reset_model(model_class, *args, **kwargs):\n",
        "    model = model_class(*args, **kwargs)\n",
        "    return model\n",
        "\n",
        "for fold_idx, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
        "    print(f\"Fold {fold_idx + 1}\")\n",
        "    print(\"=========\")\n",
        "\n",
        "    # Reset the model and optimizer\n",
        "    model = reset_model(Model, input_channels=1, input_size=64).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    # Create data loaders using SubsetRandomSampler\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "    train_loader_fold = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "    val_loader_fold = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler, num_workers=4)\n",
        "\n",
        "    # Train and evaluate\n",
        "    train(model, train_loader_fold, optimizer, criterion, epochs, device)\n",
        "    fold_avg_val_loss = evaluate(model, val_loader_fold, criterion, device)\n",
        "    evaluation_metrics.append(fold_avg_val_loss)\n",
        "\n",
        "    print(f\"Fold {fold_idx + 1} Validation Loss: {fold_avg_val_loss:.4f}\")\n",
        "    print(\"=========\")\n",
        "\n",
        "average_metric = np.mean(evaluation_metrics)\n",
        "print(f\"Average Evaluation Metric: {average_metric:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6XV3Dflja06",
        "outputId": "35056b47-3972-4581-febe-de524d95bec8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "=========\n",
            "Epoch 1, Loss: 7352.7286\n",
            "Epoch 2, Loss: 3054.5255\n",
            "Fold 1 Validation Loss: 3130.8958\n",
            "=========\n",
            "Fold 2\n",
            "=========\n",
            "Epoch 1, Loss: 6802.7679\n",
            "Epoch 2, Loss: 3051.3976\n",
            "Fold 2 Validation Loss: 2167.4744\n",
            "=========\n",
            "Average Evaluation Metric: 2649.1851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 8: Save the trained model\n",
        "model_path = \"/content/drive/MyDrive/FinalProject/trained_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "up5YazFRFP8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the trained model\n",
        "model_path = \"/content/drive/MyDrive/FinalProject/trained_model.pth\"\n",
        "model = Model(input_channels=1, input_size=64)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "rcnDOoezlloH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict head circumference from a new image\n",
        "def predict_head_circumference(image_path, model):\n",
        "    # Open and preprocess the new image\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor.float())\n",
        "\n",
        "    return output.item()  # Return the predicted head circumference as a scalar"
      ],
      "metadata": {
        "id": "Mw7sQ8uvl7TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose 10 random indices from the dataset\n",
        "num_images_to_test = 500\n",
        "random_indices = np.random.choice(len(train_csv_df), size=num_images_to_test, replace=False)\n",
        "\n",
        "# Initialize a list to store the absolute errors\n",
        "absolute_errors = []\n",
        "\n",
        "# Loop through the selected images\n",
        "for idx in random_indices:\n",
        "    image_path = os.path.join(\"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/\", train_csv_df.iloc[idx, 0])\n",
        "    ground_truth_circumference = train_csv_df.iloc[idx, 2]  # Assuming the third column contains the head circumference labels\n",
        "\n",
        "    # Call the function to predict head circumference from the image\n",
        "    predicted_circumference = predict_head_circumference(image_path, model)\n",
        "\n",
        "    # Calculate the absolute error and add it to the list\n",
        "    absolute_error = abs(predicted_circumference - ground_truth_circumference)\n",
        "    absolute_errors.append(absolute_error)\n",
        "\n",
        "    # Print the predicted and ground truth head circumferences\n",
        "    print(\"Image:\", image_path)\n",
        "    print(\"Predicted Head Circumference:\", predicted_circumference)\n",
        "    print(\"Ground Truth Head Circumference:\", ground_truth_circumference)\n",
        "    print(\"Absolute Error:\", absolute_error)\n",
        "    print(\"==============================================\")\n",
        "\n",
        "# Calculate the average absolute error\n",
        "average_absolute_error = sum(absolute_errors) / len(absolute_errors)\n",
        "print(\"Average Absolute Error:\", average_absolute_error)\n"
      ],
      "metadata": {
        "id": "PM95Xi1y1p8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Path for the new image\n",
        "# new_image_path = \"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/001_HC.png\"\n",
        "# # Call the function to predict head circumference from the new image\n",
        "# predicted_circumference = predict_head_circumference(new_image_path, model)\n",
        "# print(\"Predicted Head Circumference:\", predicted_circumference)\n"
      ],
      "metadata": {
        "id": "ztmZhcmaFeXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}