{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ofiregev/Final_Project-FetalCns/blob/main/Fetal_Cns_Final_reg_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Part 1 has done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDNOtD8OuNqn",
        "outputId": "c898bc79-858d-4b44-8aea-91e2b26561a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Part 1 has done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Determine the available hardware (CPU or GPU) and set the PyTorch device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRkJdLMg1UHT",
        "outputId": "5a3fec22-a17b-49be-e23f-6b960f4c41c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the list of images from the CSV file\n",
        "train_csv = \"/content/drive/MyDrive/FinalProject/training_set_pixel_size_and_HC.csv\"\n",
        "train_csv_df = pd.read_csv(train_csv)\n",
        "print(train_csv_df.head())\n"
      ],
      "metadata": {
        "id": "n5SWSktsumWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681ed8a3-ae82-4d82-9810-4d8de52a54ed"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     filename  pixel size(mm)  head circumference (mm)\n",
            "0  000_HC.png        0.069136                    44.30\n",
            "1  001_HC.png        0.089659                    56.81\n",
            "2  002_HC.png        0.062033                    68.75\n",
            "3  003_HC.png        0.091291                    69.00\n",
            "4  004_HC.png        0.061240                    59.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute min and max values of the head circumference\n",
        "min_hc = train_csv_df['head circumference (mm)'].min()\n",
        "max_hc = train_csv_df['head circumference (mm)'].max()\n",
        "print(min_hc, max_hc)\n",
        "\n",
        "# Normalize the labels in the dataset\n",
        "train_csv_df['Normalized_HC'] = (train_csv_df['head circumference (mm)'] - min_hc) / (max_hc - min_hc)\n",
        "output_csv = \"/content/drive/MyDrive/FinalProject/training_set_pixel_size_and_HC_no_index.csv\"\n",
        "train_csv_df.to_csv(output_csv, index=False)\n",
        "print(train_csv_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiH06H6KX2G5",
        "outputId": "c854d02d-eb8b-4f63-ff91-ca8fc09a19b9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44.3 346.4\n",
            "     filename  pixel size(mm)  head circumference (mm)  Normalized_HC\n",
            "0  000_HC.png        0.069136                    44.30       0.000000\n",
            "1  001_HC.png        0.089659                    56.81       0.041410\n",
            "2  002_HC.png        0.062033                    68.75       0.080933\n",
            "3  003_HC.png        0.091291                    69.00       0.081761\n",
            "4  004_HC.png        0.061240                    59.81       0.051341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Update CustomDataset class to use normalized labels\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.data_frame.iloc[idx, 3]  # Assuming the fourth column is the normalized label\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "0F4wcuObuccv"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_df.head()\n",
        "len(train_csv_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRVsx9GhzmEM",
        "outputId": "c6dc032b-7991-4ee1-ec8d-69b75455e796"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Define Transforms and Create Dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Assuming grayscale images\n",
        "])\n",
        "\n",
        "# Create the dataset with the updated CSV\n",
        "train_dataset = CustomDataset(csv_file=output_csv,\n",
        "                              root_dir=\"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/\",\n",
        "                              transform=transform)"
      ],
      "metadata": {
        "id": "_1eXQhF2utoI"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Create DataLoader\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "IoPz2uS-ux-U"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_channels=1, input_size=64):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 512, 3, padding=1)  # Additional Convolutional Layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        conv_output_size = input_size // 2 // 2 // 2 // 2 // 2  # Adjusted for additional pooling layers\n",
        "        self.fc1 = nn.Linear(512 * conv_output_size * conv_output_size, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.dropout = nn.Dropout(0.5)  # Increased Dropout Rate\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
        "        x = self.pool(F.relu(self.conv5(x)))  # Additional Convolutional Layer\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rEfSMMeMu1Nv"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_channels=1, input_size=64)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enSvWIyjiQkc",
        "outputId": "b25f144e-8c7c-45ac-b387-2fb94ac62981"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6: Define Training Parameters and Optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "QVo75mLhu49C"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, scheduler, criterion, epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
        "        scheduler.step()  # Step the scheduler"
      ],
      "metadata": {
        "id": "sjg4Y0ohjX6W"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "    fold_avg_val_loss = np.mean(val_losses)\n",
        "    return fold_avg_val_loss\n"
      ],
      "metadata": {
        "id": "G9u-TeagjYwQ"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import SubsetRandomSampler\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "k = 3\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "evaluation_metrics = []\n",
        "epochs = 8\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "\n",
        "\n",
        "# Define the function to reinitialize the model\n",
        "def reset_model(model_class, *args, **kwargs):\n",
        "    model = model_class(*args, **kwargs)\n",
        "    return model\n",
        "\n",
        "for fold_idx, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
        "    print(f\"Fold {fold_idx + 1}\")\n",
        "    print(\"=========\")\n",
        "\n",
        "    # Reset the model and optimizer\n",
        "    model = reset_model(Model, input_channels=1, input_size=64).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    # Create data loaders using SubsetRandomSampler\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "    train_loader_fold = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "    val_loader_fold = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n",
        "\n",
        "    # Train and evaluate\n",
        "    train(model, train_loader_fold, optimizer,scheduler, criterion, epochs, device)\n",
        "    fold_avg_val_loss = evaluate(model, val_loader_fold, criterion, device)\n",
        "    evaluation_metrics.append(fold_avg_val_loss)\n",
        "\n",
        "    print(f\"Fold {fold_idx + 1} Validation Loss: {fold_avg_val_loss:.4f}\")\n",
        "    print(\"=========\")\n",
        "\n",
        "average_metric = np.mean(evaluation_metrics)\n",
        "print(f\"Average Evaluation Metric: {average_metric:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "i6XV3Dflja06",
        "outputId": "842fde4f-57ca-4733-f775-1d33b9968788"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "=========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-105-3086a8f196dd>\", line 13, in __getitem__\n    image = Image.open(img_name)\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/Masks/214_HC.png'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-bcff484bbf4e>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mfold_avg_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mevaluation_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_avg_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-01b273187395>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, scheduler, criterion, epochs, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-105-3086a8f196dd>\", line 13, in __getitem__\n    image = Image.open(img_name)\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/Masks/214_HC.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 8: Save the trained model\n",
        "model_path = \"/content/drive/MyDrive/FinalProject/trained_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "up5YazFRFP8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the trained model\n",
        "model_path = \"/content/drive/MyDrive/FinalProject/trained_model.pth\"\n",
        "model = Model(input_channels=1, input_size=64)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "rcnDOoezlloH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_head_circumference(image_path, model, min_hc, max_hc):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor.float())\n",
        "\n",
        "    predicted_normalized_hc = output.item()\n",
        "    predicted_hc = predicted_normalized_hc * (max_hc - min_hc) + min_hc  # De-normalize the prediction\n",
        "    return predicted_hc\n"
      ],
      "metadata": {
        "id": "Mw7sQ8uvl7TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose 10 random indices from the dataset\n",
        "num_images_to_test = 500\n",
        "random_indices = np.random.choice(len(train_csv_df), size=num_images_to_test, replace=False)\n",
        "\n",
        "# Initialize a list to store the absolute errors\n",
        "absolute_errors = []\n",
        "\n",
        "# Loop through the selected images\n",
        "for idx in random_indices:\n",
        "    image_path = os.path.join(\"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/\", train_csv_df.iloc[idx, 0])\n",
        "    ground_truth_circumference = train_csv_df.iloc[idx, 2]  # Assuming the third column contains the head circumference labels\n",
        "\n",
        "    # Call the function to predict head circumference from the image\n",
        "    predicted_circumference = predict_head_circumference(image_path, model, min_hc, max_hc)\n",
        "\n",
        "    # Calculate the absolute error and add it to the list\n",
        "    absolute_error = abs(predicted_circumference - ground_truth_circumference)\n",
        "    absolute_errors.append(absolute_error)\n",
        "\n",
        "    # Print the predicted and ground truth head circumferences\n",
        "    print(\"Image:\", image_path)\n",
        "    print(\"Predicted Head Circumference:\", predicted_circumference)\n",
        "    print(\"Ground Truth Head Circumference:\", ground_truth_circumference)\n",
        "    print(\"Absolute Error:\", absolute_error)\n",
        "    print(\"==============================================\")\n",
        "\n",
        "# Calculate the average absolute error\n",
        "average_absolute_error = sum(absolute_errors) / len(absolute_errors)\n",
        "print(\"Average Absolute Error:\", average_absolute_error)\n"
      ],
      "metadata": {
        "id": "PM95Xi1y1p8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Path for the new image\n",
        "new_image_path = \"/content/drive/MyDrive/FinalProject/Dataset/training_set/training_set/001_HC.png\"\n",
        "# Call the function to predict head circumference from the new image\n",
        "predicted_circumference = predict_head_circumference(new_image_path, model, min_hc, max_hc)\n",
        "\n",
        "print(\"Predicted Head Circumference:\", predicted_circumference)\n"
      ],
      "metadata": {
        "id": "ztmZhcmaFeXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}